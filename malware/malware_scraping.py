import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
import os
import argparse

# Universal dataframe to be exported to csv
df = pd.DataFrame()

# Appending to master list
master_mal_list = []
master_ip_list = []


def clean_string(clean):
    return str(clean)[4:-5].strip()


# This code particular is suited to https://www.malware-traffic-analysis.net
parser = argparse.ArgumentParser()
parser.add_argument('-year', '--year', help='Year to scrape')
args = parser.parse_args()

saved_dir = os.path.abspath("./malware_data" + "_" + str(args.year) + ".csv")
print("The save directory is " + saved_dir)

# Input malware traffic website
url = "https://www.malware-traffic-analysis.net/" + str(args.year)
print("The url to test is " + url)
resp = requests.get(url)
soup = BeautifulSoup(resp.text, 'lxml')

# Getting the links for all the webpage of malware samples
allLinks = []
for link in soup.find_all('a', href=True):
    if "http" not in link["href"] and ".." not in link["href"]:
        temp = url + "/" + (link["href"])
        allLinks.append(temp)

# Removing duplicates in a list
allLinks = list(dict.fromkeys(allLinks))

# Initializing variables to be used

for link in allLinks:
    print("Testing " + link)
    ip_list = []
    malName = ""

    resp = requests.get(link)
    soup = BeautifulSoup(resp.text, 'lxml')
    # Getting the name of the file
    # Using regex for date
    title = soup.find_all("h2")
    for h2 in title:
        if re.findall(r"[\d]{1,2}-[\d]{1,2}-[\d]{2}", str(h2)):
            malName = clean_string(h2)

    for item in soup.find_all('li'):
        if "port" in str(item) and "[.]" in str(item):
            ip_port = clean_string(item).split("-")[0].replace("[", "").replace("]", "")
            ip_list.append(ip_port)
        else:
            continue

    if len(ip_list) == 0:
        ip_list.append("-")

    master_mal_list.append(malName)
    master_ip_list.append(ip_list)

df["malware"] = pd.Series(master_mal_list)
df["ip_list"] = pd.Series(master_ip_list)
df.to_csv(saved_dir)

# Portion to download malware files
# for link in allLinks:
# 	print("Testing " + link + " now...")
# 	if "index.html" in link:
# 		domain = link.replace("index.html", "")
# 	elif "index2.html" in link:
# 		domain = link.replace("index2.html", "")
#
# 	resp = requests.get(link)
# 	# Extracting downloadable links
# 	soup = BeautifulSoup(resp.text, 'lxml')
# 	print("Downloading files...")
# 	for specific_link in soup.find_all('a', href=True):
# 		print(specific_link["href"])
# 		if ".zip" in specific_link["href"] and "artifacts" in specific_link["href"]:
# 			download = domain + specific_link["href"]
# 			print(download)
# 			urllib.request.urlretrieve(download, filename=("./malware_samples/" + str(args.year) + "/"
# 			+ specific_link["href"]))
