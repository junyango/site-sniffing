import os
import time
import requests
from bs4 import BeautifulSoup
import lxml
import argparse
import urllib.request

# This code particular is suited to https://www.malware-traffic-analysis.net
# parser = argparse.ArgumentParser()
# parser.add_argument('-year', '--year', help='Year to scrape')
# args = parser.parse_args()

# Input malware traffic website
url = "https://www.malware-traffic-analysis.net/2019"
resp = requests.get(url)
soup = BeautifulSoup(resp.text, 'lxml')

# Getting the links for all the webpage of malware samples
allLinks = []
for link in soup.find_all('a', href=True):
	if "http" not in link["href"] and ".." not in link["href"]:
		temp = url + "/" + (link["href"])
		allLinks.append(temp)

# Removing duplicates in a list
allLinks = list(dict.fromkeys(allLinks))
print(allLinks)

for link in allLinks:
	print("Testing " + link + " now...")
	if "index.html" in link:
		domain = link.replace("index.html", "")
	elif "index2.html" in link:
		domain = link.replace("index2.html", "")
	
	resp = requests.get(link)
	# Extracting downloadable links
	soup = BeautifulSoup(resp.text, 'lxml')
	print("Downloading files...")
	for linkz in soup.find_all('a', href=True):
		print(linkz["href"])
		if ".zip" in linkz["href"] and "artifacts" in linkz["href"]:
			download = domain + linkz["href"]
			print(download)
			urllib.request.urlretrieve(download, filename=("./malware_samples/" + linkz["href"]))
